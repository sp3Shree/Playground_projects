{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentials\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# from mlxtend.regressor import StackingCVRegressor\n",
    "# import lightgbm as lgb\n",
    "# from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Stats\n",
    "from scipy.stats import skew, norm\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "# Misc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Ignore useless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "pd.options.display.max_seq_items = 8000\n",
    "pd.options.display.max_rows = 8000\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline\n",
    "from matplotlib import*\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import *\n",
    "from dtreeviz.trees import *\n",
    "from IPython.display import Image, display_svg\n",
    "\n",
    "import nltk\n",
    "#nltk.download()\n",
    "import re\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import datasets, linear_model\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from wordcloud import WordCloud\n",
    "import ipywidgets as widgets\n",
    "import pandas_profiling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from scipy.cluster.vq import kmeans, vq , whiten\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from pandas import DataFrame\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pydotplus\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "import collections\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "%matplotlib inline\n",
    "import random\n",
    "import seaborn as sns\n",
    "# import shapefile as shp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from sklearn.ensemble import GradientBoostingClassifier  #GBM algorithm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, norm\n",
    "\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV, SGDClassifier\n",
    "from sklearn import ensemble, naive_bayes, svm, tree, discriminant_analysis, neighbors, feature_selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_train = pd.read_csv(\"C:\\\\Users\\\\Shreeansh\\\\Desktop\\\\Purdue\\\\Fall\\\\Module 1\\\\Data Mining\\\\bankruptcy_Train.csv\")\n",
    "bk_train.drop_duplicates(keep=False,inplace=True)\n",
    "bk_test = pd.read_csv(\"C:\\\\Users\\\\Shreeansh\\\\Desktop\\\\Purdue\\\\Fall\\\\Module 1\\\\Data Mining\\\\bankruptcy_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(bk_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ['Attr1','Attr2','Attr3','Attr4','Attr5','Attr6','Attr7','Attr8','Attr9','Attr10',\n",
    "            'Attr11','Attr12','Attr13','Attr14','Attr15','Attr16','Attr17','Attr18','Attr19','Attr20',\n",
    "            'Attr21','Attr22','Attr23','Attr24','Attr25','Attr26','Attr27','Attr28','Attr29','Attr30',\n",
    "            'Attr31','Attr32','Attr33','Attr34','Attr35','Attr36','Attr37','Attr38','Attr39','Attr40',\n",
    "            'Attr41','Attr42','Attr43','Attr44','Attr45','Attr46','Attr47','Attr48','Attr49','Attr50',\n",
    "            'Attr51','Attr52','Attr53','Attr54','Attr55','Attr56','Attr57','Attr58','Attr59','Attr60',\n",
    "            'Attr61','Attr62','Attr63','Attr64']\n",
    "Y = ['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Dataset\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(bk_train[X], bk_train[Y], test_size=0.20, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#oversampling minority class\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from collections import Counter\n",
    "from sklearn.svm import LinearSVC\n",
    "y1= y1_train[Y]\n",
    "X1= X1_train[X]\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled = pd.DataFrame(X_resampled)\n",
    "y_resampled = pd.DataFrame(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled.columns = X\n",
    "y_resampled.columns = Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resampled.groupby(['class']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Oversampled\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.20, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Search - LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def learning_rate_010_decay_power_099(current_iter):\n",
    "    base_learning_rate = 0.1\n",
    "    lr = base_learning_rate  * np.power(.99, current_iter)\n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "def learning_rate_010_decay_power_0995(current_iter):\n",
    "    base_learning_rate = 0.1\n",
    "    lr = base_learning_rate  * np.power(.995, current_iter)\n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "def learning_rate_005_decay_power_099(current_iter):\n",
    "    base_learning_rate = 0.05\n",
    "    lr = base_learning_rate  * np.power(.99, current_iter)\n",
    "    return lr if lr > 1e-3 else 1e-3\n",
    "\n",
    "import lightgbm as lgb\n",
    "fit_params={\"early_stopping_rounds\":30, \n",
    "            \"eval_metric\" : 'auc', \n",
    "            \"eval_set\" : [(X_test,y_test)],\n",
    "            'eval_names': ['valid'],\n",
    "            #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n",
    "            'verbose': 100,\n",
    "            'categorical_feature': 'auto'}\n",
    "\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "param_test ={'num_leaves': sp_randint(6, 50), \n",
    "             'min_child_samples': sp_randint(100, 500), \n",
    "             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "\n",
    "#This parameter defines the number of HP points to be tested\n",
    "n_HP_points_to_test = 100\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\n",
    "clf = lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000)\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=clf, param_distributions=param_test, \n",
    "    n_iter=n_HP_points_to_test,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    refit=True,\n",
    "    random_state=314,\n",
    "    verbose=True)\n",
    "\n",
    "#This parameter defines the number of HP points to be tested\n",
    "n_HP_points_to_test = 100\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\n",
    "clf = lgb.LGBMClassifier(max_depth=-1, random_state=314, silent=True, metric='None', n_jobs=4, n_estimators=5000)\n",
    "gs = RandomizedSearchCV(\n",
    "    estimator=clf, param_distributions=param_test, \n",
    "    n_iter=n_HP_points_to_test,\n",
    "    scoring='roc_auc',\n",
    "    cv=3,\n",
    "    refit=True,\n",
    "    random_state=314,\n",
    "    verbose=True)\n",
    "\n",
    "gs.fit(X_train, y_train, **fit_params)\n",
    "print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search - LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sw = lgb.LGBMClassifier(**clf.get_params())\n",
    "#set optimal parameters\n",
    "clf_sw.set_params(**fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_sample_weight = GridSearchCV(estimator=clf_sw, \n",
    "                                param_grid={'scale_pos_weight':[1,2,6,12]},\n",
    "                                scoring='roc_auc',\n",
    "                                cv=5,\n",
    "                                refit=True,\n",
    "                                verbose=True)\n",
    "\n",
    "gs_sample_weight.fit(X_train, y_train, **fit_params)\n",
    "print('Best score reached: {} with params: {} '.format(gs_sample_weight.best_score_, gs_sample_weight.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_split = ShuffleSplit(n_splits = 10, test_size = .2, train_size = .8, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ensemble.AdaBoostClassifier()\n",
    "base_results = cross_validate(classifier, X_train, y_train, cv  = cv_split, return_train_score=True)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "epoch=0\n",
    "for train_score,test_score in zip(base_results['train_score'], base_results['test_score']):\n",
    "        epoch +=1       \n",
    "        print(\"epoch:\",epoch,\"train_score:\",train_score, \"test_score:\",test_score)\n",
    "print('-'*10)\n",
    "\n",
    "print('BEFORE Tuning Parameters: ', classifier.get_params())\n",
    "print(\"BEFORE Tuning Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \n",
    "print(\"BEFORE Tuning Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\n",
    "print('-'*10)\n",
    "\n",
    "cl1 = LogisticRegressionCV()\n",
    "cl2 = tree.DecisionTreeClassifier()\n",
    "cl3 = naive_bayes.GaussianNB()\n",
    "cl4 = XGBClassifier(alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.0,\n",
    "              learning_rate=0.11, max_delta_step=0.5, max_depth=15,\n",
    "              min_child_weight=2, missing=None, n_estimators=300, n_jobs=1,\n",
    "              objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0.3, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=False, subsample=0.8, verbosity=1)\n",
    "\n",
    "import lightgbm as lgb\n",
    "cl5 = lgb.LGBMClassifier(colsample_bytree = 0.952164731370897, min_child_samples = 111, min_child_weight = 0.01, num_leaves = 38, reg_alpha = 0, reg_lambda = 0.1, subsample = 0.3029313662262354)\n",
    "param_grid = {'base_estimator':[cl1, cl2, cl3]}\n",
    "\n",
    "\n",
    "tune_model = GridSearchCV(ensemble.AdaBoostClassifier(), param_grid=param_grid, scoring = 'roc_auc', cv = cv_split, return_train_score=True)\n",
    "tune_model.fit(X_train, y_train)\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"epoch:\",i,\"train_score:\",tune_model.cv_results_['split'+str(i)+'_train_score'][tune_model.best_index_],\n",
    "    \"test_score:\",tune_model.cv_results_['split'+str(i)+'_test_score'][tune_model.best_index_])\n",
    "\n",
    "print('-'*10)    \n",
    "\n",
    "\n",
    "print('AFTER Tuning Parameters: ', tune_model.best_params_)\n",
    "print(\"AFTER Tuning Training w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100))\n",
    "print(\"AFTER Tuning Test w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\n",
    "print('-'*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params={\"early_stopping_rounds\":30, \n",
    "            \"eval_metric\" : 'auc', \n",
    "            \"eval_set\" : [(X_test,y_test)],\n",
    "            'eval_names': ['valid'],\n",
    "            #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n",
    "            'verbose': 100,\n",
    "            'categorical_feature': 'auto'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADABoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = AdaBoostClassifier(base_estimator = tree.DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "                       max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort=False,\n",
    "                       random_state=None, splitter='best' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.fit(X_resampled, y_resampled)\n",
    "# make predictions for test data\n",
    "y_pred = model0.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# make predictions for test data\n",
    "y1_pred = model0.predict(X1_test)\n",
    "predictions1 = [round(value) for value in y1_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y1_test, predictions1)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_proba = model0.predict_proba(X_test)[::,1]\n",
    "print(\"Valid\",roc_auc_score(y_test,  y_pred_proba))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y1_pred_proba = model0.predict_proba(X1_test)[::,1]\n",
    "print(\"Test\",roc_auc_score(y1_test,  y1_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(colsample_bytree = 0.952164731370897, min_child_samples = 111, min_child_weight = 0.01, num_leaves = 38, reg_alpha = 0, reg_lambda = 0.1, subsample = 0.3029313662262354)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_resampled, y_resampled)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# make predictions for test data\n",
    "y1_pred = model.predict(X1_test)\n",
    "predictions1 = [round(value) for value in y1_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y1_test, predictions1)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_proba = model.predict_proba(X_test)[::,1]\n",
    "print(\"Valid\",roc_auc_score(y_test,  y_pred_proba))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y1_pred_proba = model.predict_proba(X1_test)[::,1]\n",
    "print(\"Test\",roc_auc_score(y1_test,  y1_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(bk_test.iloc[:,1:])[::,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred_proba).to_csv(\"ScoreLGB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = XGBClassifier(\n",
    "    alpha=10, base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.8, gamma=0.0,\n",
    "              learning_rate=0.11, max_delta_step=0.5, max_depth=15,\n",
    "              min_child_weight=2, missing=None, n_estimators=300, n_jobs=1,\n",
    "              objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0.3, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=False, subsample=0.8, verbosity=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = model1.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "# make predictions for test data\n",
    "y1_pred = model1.predict(X1_test)\n",
    "predictions1 = [round(value) for value in y1_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y1_test, predictions1)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_proba = model1.predict_proba(X_test)[::,1]\n",
    "print(\"Valid\",roc_auc_score(y_test,  y_pred_proba))\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "y1_pred_proba = model1.predict_proba(X1_test)[::,1]\n",
    "print(\"Test\",roc_auc_score(y1_test,  y1_pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model1.predict_proba(bk_test.iloc[:,1:])[::,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred_proba).to_csv(\"ScoreXGB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(64, activation='tanh', kernel_initializer='random_normal', input_dim=64))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(44, activation='tanh', kernel_initializer='random_normal'))\n",
    "#Third  Hidden Layer\n",
    "classifier.add(Dense(24, activation='tanh', kernel_initializer='random_normal'))\n",
    "#Fourth  Hidden Layer\n",
    "classifier.add(Dense(14, activation='tanh', kernel_initializer='random_normal'))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='random_normal'))\n",
    "\n",
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =['accuracy'])\n",
    "\n",
    "#Fitting the data to the training dataset\n",
    "classifier.fit(X_train,y_train, batch_size=50, epochs=25)\n",
    "\n",
    "eval_model=classifier.evaluate(X_train, y_train)\n",
    "# eval_model\n",
    "\n",
    "y_pred =classifier.predict(X_test)\n",
    "y_pred =(y_pred>0.7)\n",
    "y1_pred =classifier.predict(X1_test)\n",
    "y1_pred =(y1_pred>0.7)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm1 = confusion_matrix(y_test, y_pred)\n",
    "cm2 = confusion_matrix(y1_test, y1_pred)\n",
    "print(cm1,cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = model.predict_proba(bk_test.iloc[:,1:])[::,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_pred_proba).to_csv(\"Score32.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blend models in order to make the final predictions more robust to overfitting\n",
    "def blended_predictions(X):\n",
    "    return ((0.45 * model1.predict_proba(X)) +  (0.55 * model.predict_proba(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final precitions from the blended model\n",
    "blended_score = rmsle(train_labels, blended_predictions(X))\n",
    "scores['blended'] = (blended_score, 0)\n",
    "print('RMSLE score on train data:')\n",
    "print(blended_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
